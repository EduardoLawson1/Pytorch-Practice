# -*- coding: utf-8 -*-
"""PytorchFundamentals.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OtKZDweUH-0Ay0sKEGmsj7j2DDVbReM2
"""

import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
print(torch.__version__)

torch.range(0,10)

scalar = torch.tensor(7)
scalar

scalar.ndim

vector = torch.tensor([7, 7])
vector

vector.ndim

vector.shape

#MATRIX
MATRIX = torch.tensor([[7, 8],
                       [9, 10]])
MATRIX

MATRIX.ndim

# TENSOR
TENSOR = torch.tensor([[1,2 ,3],
                        ])
TENSOR

TENSOR.ndim

TENSOR.shape

#criando um tensor aleatÃ³rio de shape ou tamanho(3,4)
random_tensor = torch.rand(3, 4)
random_tensor

#criando um tenosr com shape similiar a imagem
random_image_size_tensor = torch.rand(size=(224, 224, 3))#altura, largura, canais de cores
random_image_size_tensor.shape, random_image_size_tensor.ndim

random_tensor.ndim

x_original = torch.rand(size=(224, 224, 3))
# Permute the original tensor to rearrange the axis order
x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0
x_original[0, 0, 0] = 123
print(f"Previous shape: {x_original.shape}")
print(f"New shape: {x_permuted.shape}")
print(f"Value of [0,0,0]: {x_permuted[0, 0, 0]}")

x = torch.arange(1, 10).reshape(1, 3, 3)
#x, x.shape
#x[0][2][2]
x[:, :, 2]

!nvidia-smi

torch.cuda.is_available()

# Set device type
device = "cuda" if torch.cuda.is_available() else "cpu"
device

tensor = torch.tensor([1, 2, 3])
tensor_on_gpu = tensor.to(device)
tensor_on_gpu